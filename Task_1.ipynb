{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание по обработке текстов\n",
    "\n",
    "## Предсказание цены акции по экономическим новостям\n",
    "\n",
    "Входные данные:\n",
    "* Новости о компании \"Газпром\", начиная с 2010 года\n",
    "* Стоимость акций компании \"Газпром\" на ММВБ, начиная с 2010 года\n",
    "    * цена открытия (Open)\n",
    "    * цена закрытия (ClosingPrice)\n",
    "    * максимальная цена за день (DailyHigh)\n",
    "    * минимальная цена за день (DailyLow) \n",
    "    * объем бумаг (VolumePcs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Gazprom/texts.csv', parse_dates=['date'], dayfirst=True,index_col='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-11</th>\n",
       "      <td>Спорные вопросы по оплате за оказанные в пери...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-19</th>\n",
       "      <td>\"Газпром\" готов забирать весь объем азербайдж...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text\n",
       "date                                                         \n",
       "2010-01-04                                                   \n",
       "2010-01-11   Спорные вопросы по оплате за оказанные в пери...\n",
       "2010-01-19   \"Газпром\" готов забирать весь объем азербайдж..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_index(ascending=True, inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pr_all = pd.read_csv('Gazprom/gazprom_prices.csv', sep=';', decimal=',', parse_dates=['Date'],\n",
    "                    dayfirst=True, index_col='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>DailyHigh</th>\n",
       "      <th>DailyLow</th>\n",
       "      <th>VolumePcs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-11</th>\n",
       "      <td>192.50</td>\n",
       "      <td>194.5</td>\n",
       "      <td>196.90</td>\n",
       "      <td>191.00</td>\n",
       "      <td>59815603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-12</th>\n",
       "      <td>194.00</td>\n",
       "      <td>191.8</td>\n",
       "      <td>195.80</td>\n",
       "      <td>190.55</td>\n",
       "      <td>43482579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-13</th>\n",
       "      <td>189.72</td>\n",
       "      <td>189.3</td>\n",
       "      <td>191.86</td>\n",
       "      <td>188.30</td>\n",
       "      <td>52416087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open  ClosingPrice  DailyHigh  DailyLow  VolumePcs\n",
       "Date                                                            \n",
       "2010-01-11  192.50         194.5     196.90    191.00   59815603\n",
       "2010-01-12  194.00         191.8     195.80    190.55   43482579\n",
       "2010-01-13  189.72         189.3     191.86    188.30   52416087"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_all.sort_index(ascending=True, inplace=True)\n",
    "pr_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pymorphy2 \n",
    "import pymystem3\n",
    "import codecs\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh\n",
    "import seaborn as sns\n",
    "import random\n",
    "from pylab import pcolor, show, colorbar, xticks, yticks\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1203 entries, 2010-01-04 to 2017-11-09\n",
      "Data columns (total 1 columns):\n",
      "text    1203 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 18.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, (1203, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info(), df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1988 entries, 2010-01-11 to 2017-12-08\n",
      "Data columns (total 5 columns):\n",
      "Open            1964 non-null float64\n",
      "ClosingPrice    1988 non-null float64\n",
      "DailyHigh       1986 non-null float64\n",
      "DailyLow        1986 non-null float64\n",
      "VolumePcs       1988 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 93.2 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, (1988, 5))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_all.info(), pr_all.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 1. Вводная\n",
    "\n",
    "Проведите предобработку текстов: если считаете нужным, выполните токенизацию, приведение к нижнему регистру, лемматизацию и/или стемминг. Ответьте на следующие вопросы:\n",
    "* Есть ли корреляция между средней длинной текста за день и ценой закрытия?\n",
    "* Есть ли корреляция между количеством упоминаний Алексея Миллера  и ценой закрытия? Учтите разные варианты написания имени.\n",
    "* Упоминаний какого газопровода в статьях больше: \n",
    "    * \"северный поток\"\n",
    "    * \"турецкий поток\"?\n",
    "* О каких санкциях пишут в статьях?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Токенизация и приведение к нижнему регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile(\"[А-Яа-я----]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    return \" \".join(regex.findall(text))\n",
    "\n",
    "\n",
    "df.text = df.text.str.lower()\n",
    "df.text = df.text.apply(words_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2010-01-04                                                     \n",
       "2010-01-11    спорные вопросы по оплате за оказанные в перио...\n",
       "2010-01-19    газпром готов забирать весь объем азербайджанс...\n",
       "2010-01-28    консорциум во главе с российским оао газпром н...\n",
       "2010-02-01    газпром не исключает в г выпуска облигаций при...\n",
       "2010-02-03    переговоры оао газпром с оператором проекта са...\n",
       "2010-02-04    российский газовый монополист компания газпром...\n",
       "2010-02-15    российский газпром сообщил о планах увеличения...\n",
       "2010-03-10    подконтрольный газпрому нефтедобытчик газпром ...\n",
       "2010-03-22    газпром назвал участников конкурса по отбору о...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Удаление стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между', 'оао', 'руб', 'евро', 'долл', 'тыс', 'млн', 'млрд', 'также', 'это', 'наш', 'т', 'д', '-', '-', 'вице', 'эль', 'г', 'ъ']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "mystopwords = stopwords.words('russian') + ['оао','руб', 'евро', 'долл', 'тыс', 'млн', 'млрд', 'также',\n",
    "                                            'это', 'наш', 'т', 'д', '-', '-', 'вице', 'эль', 'г', 'ъ']\n",
    "\n",
    "print(mystopwords)\n",
    "def  remove_stopwords(text, mystopwords = mystopwords):\n",
    "    try:\n",
    "        return \" \".join([token for token in text.split() if not token in mystopwords])\n",
    "    except:\n",
    "        return \"\"\n",
    "df.text = df.text.apply(remove_stopwords) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from pymystem3 import Mystem\n",
    "\n",
    "m = Mystem()\n",
    "def lemmatize(text, mystem=m):\n",
    "    try:\n",
    "        return \"\".join(m.lemmatize(text)).strip()  \n",
    "    except:\n",
    "        return \" \"\n",
    "\n",
    "df.text = df.text.apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2010-01-04                                                     \n",
       "2010-01-11    спорный вопрос оплата оказывать период гг услу...\n",
       "2010-01-19    газпром готовый забирать весь объем азербайджа...\n",
       "2010-01-28    консорциум глава российский газпром нефть четв...\n",
       "2010-02-01    газпром исключать выпуск облигация примерно по...\n",
       "2010-02-03    переговоры газпром оператор проект сахалин- ко...\n",
       "2010-02-04    российский газовый монополист компания газпром...\n",
       "2010-02-15    российский газпром сообщать план увеличение до...\n",
       "2010-03-10    подконтрольный газпром нефтедобытчик газпром н...\n",
       "2010-03-22    газпром называть участник конкурс отбор органи...\n",
       "2010-03-26    глава газпром новатэк леонид михельсон алексей...\n",
       "2010-03-30    итог чистый прибыль газпром нефть рсба выраста...\n",
       "2010-03-31    сегодня пройти годовой собрание акционер белор...\n",
       "2010-04-07    украина полностью расплачиваться мартовский по...\n",
       "2010-04-12    крупный мир производитель газ газпром договари...\n",
       "2010-04-19    министр природный ресурс рф юрий трутнеть расс...\n",
       "2010-04-20    группа видео интернешнл смочь увеличивать прод...\n",
       "2010-04-22    газпром нефть намерен создавать республика алт...\n",
       "2010-04-26    российский власть готовый отказываться отзыв т...\n",
       "2010-04-27    российский газпром итальянский уступать францу...\n",
       "2010-05-05    газпром-медиа создавать один площадка интернет...\n",
       "2010-05-19    газпромбанк скупать акция свой топ-менеджер по...\n",
       "2010-05-25    российский газоэкспортный монополия газпром по...\n",
       "2010-05-26    соглашение вхождение французский проект строит...\n",
       "2010-05-28    российский концерн газпром украинский госкомпа...\n",
       "2010-06-07    газпром видеть обозримый будущее возможность с...\n",
       "2010-06-09    газпром готовый приступать практический реализ...\n",
       "2010-06-11    французский нефтяной компания партнер российск...\n",
       "2010-06-16    российский компания газпром направлять адрес к...\n",
       "2010-06-17    первичный публичный размещение акция российски...\n",
       "                                    ...                        \n",
       "2017-07-18    российский фонд прямой инвестиция рфпи владеть...\n",
       "2017-07-24    считать положительный разрешение ситуация испо...\n",
       "2017-07-26    татнефть хотеть потеснить крупный нефтекомпани...\n",
       "2017-07-27    статья опубликовывать один ресурс спортивный с...\n",
       "2017-07-28    спустя полгода газпром снова получать возможно...\n",
       "2017-08-03    россия оставаться надежный гарант энергобезопа...\n",
       "2017-08-07    оглядка успех турецкий телесага великолепный в...\n",
       "2017-08-10    газпром отрапортовать -процентный загрузка газ...\n",
       "2017-08-14    становиться известно газпром нефть возникать с...\n",
       "2017-08-16    градообразующий предприятие инта ао интауголь ...\n",
       "2017-08-17    газпром уверенно идти новый абсолютный экспорт...\n",
       "2017-08-21    уход пост канцлер фрг ангел меркель собираться...\n",
       "2017-08-31    выручка газпром-медиа первый полугодие расти в...\n",
       "2017-09-04    роснефть первый крупный российский госкомпания...\n",
       "2017-09-07    помощник президент россия андрей белоусов заяв...\n",
       "2017-09-08    газпром нафтогаз ожидать смочь договариваться ...\n",
       "2017-09-12    интерес традиционный тепловой генерация возобн...\n",
       "2017-09-13    сегодня банк россия опубликовывать свой сайт н...\n",
       "2017-09-18    газпром впервые год вернуть роль ключевой пост...\n",
       "2017-09-22    газпром новатэк мочь принимать участие комплек...\n",
       "2017-09-29    становиться известно конкурент начинать разбир...\n",
       "2017-10-04    спутниковый оператор нтв-плюс последний время ...\n",
       "2017-10-05    газпром нефть пробуривать первый скважина аяшс...\n",
       "2017-10-13    газпром подписывать контракт словения поставка...\n",
       "2017-10-20    российский прокатчик второй год приходиться ра...\n",
       "2017-10-23    новатэк который пять год собираться запускать ...\n",
       "2017-10-30    становиться известно известный рынок риск-мене...\n",
       "2017-11-01    новый редакция американский санкция ставить уг...\n",
       "2017-11-08    предполагать газпром воспользоваться жалоба ин...\n",
       "2017-11-09    компания рассчитывать решение газовый спор укр...\n",
       "Name: text, Length: 1203, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Проверяем, есть ли корреляция между длиной текстов и ценой закрытия, графически и численно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['len_data'] = df.text.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intersection = pr_all.join(df, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1b5b2be0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD3CAYAAAANMK+RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFQqFokX4f21OaO10M00jAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b54d6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=intersection.len_data, y=intersection.ClosingPrice, alpha=0.8, s=15.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pearson': 0.012273956759408979, 'spearman': -0.008241392638395996, 'kendall': -0.0060826355701091303}\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "x = intersection.len_data\n",
    "y = intersection.ClosingPrice\n",
    "corr = {}\n",
    "corr['pearson'], _ = stats.pearsonr(x,y)\n",
    "corr['spearman'], _ = stats.spearmanr(x,y)\n",
    "corr['kendall'], _ = stats.kendalltau(x,y)\n",
    "\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Можно сделать вывод о том что корреляция не наблюдается"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Проверяем, есть ли корреляция между количеством упоминаний Алексея Миллера и ценой закрытия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prog = re.compile(r'миллер')\n",
    "df['Miller'] = df.text.apply(prog.findall)\n",
    "df['Miller_count'] = df.Miller.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intersection = pr_all.join(df, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pearson': 0.010635076467578013, 'spearman': 0.023244353525710616, 'kendall': 0.018954081964142402}\n"
     ]
    }
   ],
   "source": [
    "x = intersection.Miller_count\n",
    "y = intersection.ClosingPrice\n",
    "corr = {}\n",
    "corr['pearson'], _ = stats.pearsonr(x,y)\n",
    "corr['spearman'], _ = stats.spearmanr(x,y)\n",
    "corr['kendall'], _ = stats.kendalltau(x,y)\n",
    "\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Можно сделать вывод о том что корреляция не наблюдается"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Проверяем упоминаний какого газопровода в статьях больше: \n",
    "    * \"северный поток\"\n",
    "    * \"турецкий поток\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 39)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prog = re.compile(r'северный поток')\n",
    "df['north_stream'] = df.text.apply(prog.findall)\n",
    "df['north_stream_count'] = df.north_stream.apply(len)\n",
    "\n",
    "prog = re.compile(r'турецкий поток')\n",
    "df['turkish_stream'] = df.text.apply(prog.findall)\n",
    "df['turkish_stream_count'] = df.turkish_stream.apply(len)\n",
    "\n",
    "north_stream_mentioned = df.north_stream_count.sum()\n",
    "turkish_stream_mentioned = df.turkish_stream_count.sum()\n",
    "\n",
    "north_stream_mentioned, turkish_stream_mentioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Можно сделать вывод о том число упоминаний проекта Турецкий поток больше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Классификационная\n",
    "Вам предстоит решить следующую задачу: по текстам новостей за день определить, вырастет или понизится цена закрытия.\n",
    "Для этого:\n",
    "* бинаризуйте признак \"цена закрытия\":  новый признак ClosingPrice_bin равен 1, если по сравнению со вчера цена не упала, и 0 – в обратном случаея;\n",
    "* составьте бучающее и тестовое множество: данные до начала 2016 года используются для обучения, данные с 2016 года и позже – для тестирования.\n",
    "\n",
    "Таким образом, в каждлый момент времени мы знаем: \n",
    "* ClosingPrice_bin – бинарый целевой признак\n",
    "* слова из статей, опубликованных в этот день – объясняющие признаки\n",
    "\n",
    "В этой части задания вам нужно сделать baseline алгоритм и попытаться его улучшить в следующей части. \n",
    "\n",
    "Используйте любой известный вам алгоритм классификации текстов для того, Используйте $tf-idf$ преобразование, сингулярное разложение, нормировку признакого пространства и любые другие техники обработки данных, которые вы считаете нужным. Используйте accuracy и F-measure для оценки качества классификации. Покажите, как  $tf-idf$ преобразование или сингулярное разложение или любая другая использованная вами техника влияет на качество классификации.\n",
    "Если у выбранного вами алгоритма есть гиперпараметры (например, $\\alpha$ в преобразовании Лапласа для метода наивного Байеса), покажите, как изменение гиперпараметра влияет на качество классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Бинаризируем признак изменения цены закрытия и разбиваем выборку на обучающую и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_data = pr_all[['ClosingPrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClosingPrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-11</th>\n",
       "      <td>194.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-12</th>\n",
       "      <td>191.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-13</th>\n",
       "      <td>189.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ClosingPrice\n",
       "Date                    \n",
       "2010-01-11         194.5\n",
       "2010-01-12         191.8\n",
       "2010-01-13         189.3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClosingPrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-11</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-12</th>\n",
       "      <td>0.986118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-13</th>\n",
       "      <td>0.986966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ClosingPrice\n",
       "Date                    \n",
       "2010-01-11           NaN\n",
       "2010-01-12      0.986118\n",
       "2010-01-13      0.986966"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_data = pd.DataFrame(p_data.ClosingPrice / p_data.ClosingPrice.shift(1))\n",
    "change_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>Change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-11</th>\n",
       "      <td>194.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-12</th>\n",
       "      <td>191.80</td>\n",
       "      <td>0.986118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-13</th>\n",
       "      <td>189.30</td>\n",
       "      <td>0.986966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-14</th>\n",
       "      <td>190.83</td>\n",
       "      <td>1.008082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ClosingPrice    Change\n",
       "Date                              \n",
       "2010-01-11        194.50       NaN\n",
       "2010-01-12        191.80  0.986118\n",
       "2010-01-13        189.30  0.986966\n",
       "2010-01-14        190.83  1.008082"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_data.rename(columns={'ClosingPrice' : 'Change'}, inplace=True)\n",
    "p_data = pd.concat([p_data, change_data], axis = 1)\n",
    "p_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>Change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-12</th>\n",
       "      <td>191.80</td>\n",
       "      <td>0.986118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-13</th>\n",
       "      <td>189.30</td>\n",
       "      <td>0.986966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-14</th>\n",
       "      <td>190.83</td>\n",
       "      <td>1.008082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-15</th>\n",
       "      <td>187.86</td>\n",
       "      <td>0.984436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ClosingPrice    Change\n",
       "Date                              \n",
       "2010-01-12        191.80  0.986118\n",
       "2010-01-13        189.30  0.986966\n",
       "2010-01-14        190.83  1.008082\n",
       "2010-01-15        187.86  0.984436"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>Change</th>\n",
       "      <th>ClosingPrice_bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-12</th>\n",
       "      <td>191.80</td>\n",
       "      <td>0.986118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-13</th>\n",
       "      <td>189.30</td>\n",
       "      <td>0.986966</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-14</th>\n",
       "      <td>190.83</td>\n",
       "      <td>1.008082</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ClosingPrice    Change  ClosingPrice_bin\n",
       "Date                                                \n",
       "2010-01-12        191.80  0.986118                 0\n",
       "2010-01-13        189.30  0.986966                 0\n",
       "2010-01-14        190.83  1.008082                 1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data['ClosingPrice_bin'] = (p_data.Change // 1).astype(dtype='int')\n",
    "p_data.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intersection = p_data.join(df, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>Change</th>\n",
       "      <th>ClosingPrice_bin</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-19</th>\n",
       "      <td>189.76</td>\n",
       "      <td>0.996639</td>\n",
       "      <td>0</td>\n",
       "      <td>газпром готовый забирать весь объем азербайджа...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-28</th>\n",
       "      <td>182.30</td>\n",
       "      <td>1.001593</td>\n",
       "      <td>1</td>\n",
       "      <td>консорциум глава российский газпром нефть четв...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ClosingPrice    Change  ClosingPrice_bin  \\\n",
       "2010-01-19        189.76  0.996639                 0   \n",
       "2010-01-28        182.30  1.001593                 1   \n",
       "\n",
       "                                                         text  \n",
       "2010-01-19  газпром готовый забирать весь объем азербайджа...  \n",
       "2010-01-28  консорциум глава российский газпром нефть четв...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.51209\n",
       "1    0.48791\n",
       "Name: ClosingPrice_bin, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection.ClosingPrice_bin.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f10b160>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADsCAYAAABkIV3JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQRS6IAjCOEEUuiAIwjjh/wM2E2eKJKAQggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c0aa6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "intersection.ClosingPrice.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train = intersection[:'2015']\n",
    "data_test = intersection['2016':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = data_train['text']\n",
    "y_train = data_train['ClosingPrice_bin']\n",
    "X_test = data_test['text']\n",
    "y_test = data_test['ClosingPrice_bin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Используем CountVectorizer и строим базовые классификаторы с сеточным подбором гиперпараметров, проверяем возможность улучшения с помощью tf-idf преобразования и снижения размерности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(2904)\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 154790)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_list = X_train.tolist()\n",
    "vect = CountVectorizer(ngram_range=(1,4))\n",
    "X_train_counts = vect.fit_transform(X_train_list)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258, 154790)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_list = X_test.tolist()\n",
    "X_test_counts = vect.transform(X_test_list)\n",
    "X_test_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state=2904)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=2904, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'C': [.1, .2, .3, .4, .5, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(estimator=classifier, param_grid=params, scoring='accuracy', verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ................................ C=0.1, score=0.48, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ................................ C=0.1, score=0.51, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ................. C=0.1, score=0.49333333333333335, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=0.2 ...........................................................\n",
      "[CV] ................. C=0.2, score=0.47333333333333333, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=0.2 ...........................................................\n",
      "[CV] .................. C=0.2, score=0.5033333333333333, total=   0.1s\n",
      "[CV] C=0.2 ...........................................................\n",
      "[CV] .................. C=0.2, score=0.4866666666666667, total=   0.1s\n",
      "[CV] C=0.3 ...........................................................\n",
      "[CV] ................................ C=0.3, score=0.47, total=   0.2s\n",
      "[CV] C=0.3 ...........................................................\n",
      "[CV] .................. C=0.3, score=0.5033333333333333, total=   0.2s\n",
      "[CV] C=0.3 ...........................................................\n",
      "[CV] .................. C=0.3, score=0.4866666666666667, total=   0.2s\n",
      "[CV] C=0.4 ...........................................................\n",
      "[CV] ................................ C=0.4, score=0.47, total=   0.2s\n",
      "[CV] C=0.4 ...........................................................\n",
      "[CV] .................. C=0.4, score=0.5033333333333333, total=   0.2s\n",
      "[CV] C=0.4 ...........................................................\n",
      "[CV] ................................ C=0.4, score=0.49, total=   0.2s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[CV] .................. C=0.5, score=0.4633333333333333, total=   0.2s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[CV] ................................. C=0.5, score=0.5, total=   0.2s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[CV] ................................ C=0.5, score=0.49, total=   0.2s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .................... C=1, score=0.4633333333333333, total=   0.2s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .................... C=1, score=0.5066666666666667, total=   0.2s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .................................. C=1, score=0.48, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    4.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.33 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=2904, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.1, 0.2, 0.3, 0.4, 0.5, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=5)"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49444444444444446"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:   0.46\n",
      "Recall:   0.46\n",
      "F1-measure:   0.46\n",
      "Accuracy:   0.46\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.42      0.46       140\n",
      "          1       0.42      0.50      0.46       118\n",
      "\n",
      "avg / total       0.46      0.46      0.46       258\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAEFCAYAAAAoprYVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23407c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predictions, average='macro')))\n",
    "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, predictions, average='macro')))\n",
    "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, predictions, average='macro')))\n",
    "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(classification_report(y_test, predictions))\n",
    "labels = clf.classes_\n",
    "sns.heatmap(data=confusion_matrix(y_test, predictions), annot=True, fmt=\"d\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "reducer = TruncatedSVD(n_components=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = transformer.fit_transform(X_train_counts)\n",
    "b = reducer.fit_transform(a)\n",
    "c = transformer.fit_transform(X_test_counts)\n",
    "d = reducer.fit_transform(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(estimator=classifier, param_grid=params, scoring='accuracy', verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] .................. C=0.1, score=0.5033333333333333, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ................. C=0.1, score=0.48333333333333334, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ................................. C=0.1, score=0.5, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=0.2 ...........................................................\n",
      "[CV] ................. C=0.2, score=0.48333333333333334, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] C=0.2 ...........................................................\n",
      "[CV] .................. C=0.2, score=0.4666666666666667, total=   0.0s\n",
      "[CV] C=0.2 ...........................................................\n",
      "[CV] .................. C=0.2, score=0.5166666666666667, total=   0.0s\n",
      "[CV] C=0.3 ...........................................................\n",
      "[CV] .................. C=0.3, score=0.4866666666666667, total=   0.0s\n",
      "[CV] C=0.3 ...........................................................\n",
      "[CV] .................. C=0.3, score=0.4633333333333333, total=   0.0s\n",
      "[CV] C=0.3 ...........................................................\n",
      "[CV] .................. C=0.3, score=0.5033333333333333, total=   0.0s\n",
      "[CV] C=0.4 ...........................................................\n",
      "[CV] ................. C=0.4, score=0.49333333333333335, total=   0.0s\n",
      "[CV] C=0.4 ...........................................................\n",
      "[CV] ................................ C=0.4, score=0.48, total=   0.0s\n",
      "[CV] C=0.4 ...........................................................\n",
      "[CV] ................. C=0.4, score=0.49666666666666665, total=   0.0s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[CV] ................. C=0.5, score=0.49333333333333335, total=   0.0s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[CV] ................. C=0.5, score=0.49333333333333335, total=   0.0s\n",
      "[CV] C=0.5 ...........................................................\n",
      "[CV] .................. C=0.5, score=0.4866666666666667, total=   0.0s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .................... C=1, score=0.4766666666666667, total=   0.0s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .................... C=1, score=0.5066666666666667, total=   0.0s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] .................... C=1, score=0.4866666666666667, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=2904, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.1, 0.2, 0.3, 0.4, 0.5, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=5)"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(b, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49555555555555558"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:   0.48\n",
      "Recall:   0.49\n",
      "F1-measure:   0.46\n",
      "Accuracy:   0.51\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.76      0.63       140\n",
      "          1       0.43      0.21      0.28       118\n",
      "\n",
      "avg / total       0.49      0.51      0.47       258\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAEFCAYAAAAoprYVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22269550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predictions, average='macro')))\n",
    "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, predictions, average='macro')))\n",
    "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, predictions, average='macro')))\n",
    "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(classification_report(y_test, predictions))\n",
    "labels = clf.classes_\n",
    "sns.heatmap(data=confusion_matrix(y_test, predictions), annot=True, fmt=\"d\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)>"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "\n",
    "classifier.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'alpha': [.001, .01, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(estimator=classifier, param_grid=params, verbose=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] .......................... alpha=0.001, score=0.56, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ........................... alpha=0.001, score=0.5, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ............ alpha=0.001, score=0.5533333333333333, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] alpha=0.01 ......................................................\n",
      "[CV] ............. alpha=0.01, score=0.5433333333333333, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] alpha=0.01 ......................................................\n",
      "[CV] ............................ alpha=0.01, score=0.5, total=   0.0s\n",
      "[CV] alpha=0.01 ......................................................\n",
      "[CV] ............. alpha=0.01, score=0.5333333333333333, total=   0.0s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ............................ alpha=0.1, score=0.53, total=   0.0s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ............. alpha=0.1, score=0.49333333333333335, total=   0.0s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ............................ alpha=0.1, score=0.51, total=   0.0s\n",
      "[CV] alpha=0.2 .......................................................\n",
      "[CV] .............. alpha=0.2, score=0.5333333333333333, total=   0.0s\n",
      "[CV] alpha=0.2 .......................................................\n",
      "[CV] ............. alpha=0.2, score=0.47333333333333333, total=   0.0s\n",
      "[CV] alpha=0.2 .......................................................\n",
      "[CV] .............. alpha=0.2, score=0.5066666666666667, total=   0.0s\n",
      "[CV] alpha=0.3 .......................................................\n",
      "[CV] .............. alpha=0.3, score=0.5366666666666666, total=   0.0s\n",
      "[CV] alpha=0.3 .......................................................\n",
      "[CV] ............. alpha=0.3, score=0.48333333333333334, total=   0.0s\n",
      "[CV] alpha=0.3 .......................................................\n",
      "[CV] ............. alpha=0.3, score=0.49666666666666665, total=   0.0s\n",
      "[CV] alpha=0.4 .......................................................\n",
      "[CV] .............. alpha=0.4, score=0.5366666666666666, total=   0.0s\n",
      "[CV] alpha=0.4 .......................................................\n",
      "[CV] ............................ alpha=0.4, score=0.49, total=   0.0s\n",
      "[CV] alpha=0.4 .......................................................\n",
      "[CV] ............. alpha=0.4, score=0.49333333333333335, total=   0.0s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] ............................ alpha=0.5, score=0.54, total=   0.0s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] ............. alpha=0.5, score=0.49666666666666665, total=   0.0s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] ............. alpha=0.5, score=0.49666666666666665, total=   0.0s\n",
      "[CV] alpha=0.6 .......................................................\n",
      "[CV] .............. alpha=0.6, score=0.5433333333333333, total=   0.0s\n",
      "[CV] alpha=0.6 .......................................................\n",
      "[CV] .............. alpha=0.6, score=0.5033333333333333, total=   0.0s\n",
      "[CV] alpha=0.6 .......................................................\n",
      "[CV] ............................ alpha=0.6, score=0.51, total=   0.0s\n",
      "[CV] alpha=0.7 .......................................................\n",
      "[CV] ............................ alpha=0.7, score=0.54, total=   0.0s\n",
      "[CV] alpha=0.7 .......................................................\n",
      "[CV] .............. alpha=0.7, score=0.5033333333333333, total=   0.0s\n",
      "[CV] alpha=0.7 .......................................................\n",
      "[CV] .............. alpha=0.7, score=0.5166666666666667, total=   0.0s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "[CV] .............. alpha=0.8, score=0.5366666666666666, total=   0.0s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "[CV] ............. alpha=0.8, score=0.49666666666666665, total=   0.0s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "[CV] .............. alpha=0.8, score=0.5166666666666667, total=   0.0s\n",
      "[CV] alpha=0.9 .......................................................\n",
      "[CV] .............. alpha=0.9, score=0.5466666666666666, total=   0.0s\n",
      "[CV] alpha=0.9 .......................................................\n",
      "[CV] ............. alpha=0.9, score=0.49333333333333335, total=   0.0s\n",
      "[CV] alpha=0.9 .......................................................\n",
      "[CV] .............. alpha=0.9, score=0.5133333333333333, total=   0.0s\n",
      "[CV] alpha=1 .........................................................\n",
      "[CV] ................ alpha=1, score=0.5433333333333333, total=   0.0s\n",
      "[CV] alpha=1 .........................................................\n",
      "[CV] ............... alpha=1, score=0.49666666666666665, total=   0.0s\n",
      "[CV] alpha=1 .........................................................\n",
      "[CV] .............................. alpha=1, score=0.52, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.62 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=5)"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5377777777777778, {'alpha': 0.001})"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_, clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:   0.53\n",
      "Recall:   0.53\n",
      "F1-measure:   0.53\n",
      "Accuracy:   0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.59      0.58       140\n",
      "          1       0.50      0.48      0.49       118\n",
      "\n",
      "avg / total       0.54      0.54      0.54       258\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAEFCAYAAAAoprYVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJAVitCUpkP8FoS4vtgt3A9UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4e3ebc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predictions, average='macro')))\n",
    "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, predictions, average='macro')))\n",
    "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, predictions, average='macro')))\n",
    "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(classification_report(y_test, predictions))\n",
    "labels = clf.classes_\n",
    "sns.heatmap(data=confusion_matrix(y_test, predictions), annot=True, fmt=\"d\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(estimator=classifier, param_grid=params, scoring='accuracy', verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ............ alpha=0.001, score=0.5433333333333333, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ............ alpha=0.001, score=0.5266666666666666, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] alpha=0.001 .....................................................\n",
      "[CV] ............ alpha=0.001, score=0.5233333333333333, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] alpha=0.01 ......................................................\n",
      "[CV] ............. alpha=0.01, score=0.5566666666666666, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] alpha=0.01 ......................................................\n",
      "[CV] ............. alpha=0.01, score=0.5066666666666667, total=   0.0s\n",
      "[CV] alpha=0.01 ......................................................\n",
      "[CV] ............ alpha=0.01, score=0.49666666666666665, total=   0.0s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ............................ alpha=0.1, score=0.55, total=   0.0s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ............. alpha=0.1, score=0.48333333333333334, total=   0.0s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ............................. alpha=0.1, score=0.5, total=   0.0s\n",
      "[CV] alpha=0.2 .......................................................\n",
      "[CV] ............................ alpha=0.2, score=0.54, total=   0.0s\n",
      "[CV] alpha=0.2 .......................................................\n",
      "[CV] ............. alpha=0.2, score=0.49333333333333335, total=   0.0s\n",
      "[CV] alpha=0.2 .......................................................\n",
      "[CV] .............. alpha=0.2, score=0.5033333333333333, total=   0.0s\n",
      "[CV] alpha=0.3 .......................................................\n",
      "[CV] .............. alpha=0.3, score=0.5466666666666666, total=   0.0s\n",
      "[CV] alpha=0.3 .......................................................\n",
      "[CV] ............................ alpha=0.3, score=0.48, total=   0.0s\n",
      "[CV] alpha=0.3 .......................................................\n",
      "[CV] .............. alpha=0.3, score=0.5133333333333333, total=   0.0s\n",
      "[CV] alpha=0.4 .......................................................\n",
      "[CV] .............. alpha=0.4, score=0.5433333333333333, total=   0.0s\n",
      "[CV] alpha=0.4 .......................................................\n",
      "[CV] .............. alpha=0.4, score=0.4766666666666667, total=   0.0s\n",
      "[CV] alpha=0.4 .......................................................\n",
      "[CV] .............. alpha=0.4, score=0.5166666666666667, total=   0.0s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] .............. alpha=0.5, score=0.5333333333333333, total=   0.0s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] .............. alpha=0.5, score=0.4766666666666667, total=   0.0s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] .............. alpha=0.5, score=0.5166666666666667, total=   0.0s\n",
      "[CV] alpha=0.6 .......................................................\n",
      "[CV] .............. alpha=0.6, score=0.5333333333333333, total=   0.0s\n",
      "[CV] alpha=0.6 .......................................................\n",
      "[CV] ............................ alpha=0.6, score=0.47, total=   0.0s\n",
      "[CV] alpha=0.6 .......................................................\n",
      "[CV] ............................ alpha=0.6, score=0.52, total=   0.0s\n",
      "[CV] alpha=0.7 .......................................................\n",
      "[CV] ............................ alpha=0.7, score=0.54, total=   0.0s\n",
      "[CV] alpha=0.7 .......................................................\n",
      "[CV] ............................ alpha=0.7, score=0.47, total=   0.0s\n",
      "[CV] alpha=0.7 .......................................................\n",
      "[CV] .............. alpha=0.7, score=0.5166666666666667, total=   0.0s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "[CV] .............. alpha=0.8, score=0.5366666666666666, total=   0.0s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "[CV] ............................ alpha=0.8, score=0.48, total=   0.0s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "[CV] ............................ alpha=0.8, score=0.51, total=   0.0s\n",
      "[CV] alpha=0.9 .......................................................\n",
      "[CV] ............................ alpha=0.9, score=0.55, total=   0.0s\n",
      "[CV] alpha=0.9 .......................................................\n",
      "[CV] .............. alpha=0.9, score=0.4866666666666667, total=   0.0s\n",
      "[CV] alpha=0.9 .......................................................\n",
      "[CV] ............................ alpha=0.9, score=0.52, total=   0.0s\n",
      "[CV] alpha=1 .........................................................\n",
      "[CV] .............................. alpha=1, score=0.55, total=   0.0s\n",
      "[CV] alpha=1 .........................................................\n",
      "[CV] ................ alpha=1, score=0.4866666666666667, total=   0.0s\n",
      "[CV] alpha=1 .........................................................\n",
      "[CV] ................ alpha=1, score=0.5133333333333333, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=5)"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(a, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.53111111111111109, {'alpha': 0.001})"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_, clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:   0.52\n",
      "Recall:   0.53\n",
      "F1-measure:   0.52\n",
      "Accuracy:   0.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.55      0.56       140\n",
      "          1       0.48      0.50      0.49       118\n",
      "\n",
      "avg / total       0.53      0.53      0.53       258\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAEFCAYAAAAoprYVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x234e1128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predictions, average='macro')))\n",
    "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, predictions, average='macro')))\n",
    "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, predictions, average='macro')))\n",
    "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(classification_report(y_test, predictions))\n",
    "labels = clf.classes_\n",
    "sns.heatmap(data=confusion_matrix(y_test, predictions), annot=True, fmt=\"d\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = SGDClassifier(random_state=2904, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=2904,\n",
       "       shuffle=True, tol=None, verbose=5, warm_start=False)>"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'alpha' : [.0001, .005, .01, .05, .1, .5 ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(estimator=classifier, param_grid=params, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 2048.06, NNZs: 60859, Bias: 0.728416, T: 600, Avg. loss: 171.457419\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1740.36, NNZs: 84105, Bias: -0.134857, T: 1200, Avg. loss: 52.240329\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1430.22, NNZs: 90263, Bias: 0.162531, T: 1800, Avg. loss: 11.850746\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1192.42, NNZs: 92359, Bias: 0.189633, T: 2400, Avg. loss: 1.310534\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1022.04, NNZs: 93435, Bias: 0.192008, T: 3000, Avg. loss: 0.244672\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 2088.21, NNZs: 62606, Bias: -0.285101, T: 600, Avg. loss: 175.540390\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1754.42, NNZs: 81220, Bias: -0.305642, T: 1200, Avg. loss: 44.949547\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1448.24, NNZs: 86905, Bias: -0.033108, T: 1800, Avg. loss: 8.729869\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1214.10, NNZs: 89051, Bias: 0.125970, T: 2400, Avg. loss: 2.246413\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1036.08, NNZs: 89541, Bias: 0.180224, T: 3000, Avg. loss: 0.656722\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1962.87, NNZs: 51464, Bias: 0.973087, T: 600, Avg. loss: 155.000910\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1689.26, NNZs: 71776, Bias: 0.688266, T: 1200, Avg. loss: 57.393935\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1413.88, NNZs: 79214, Bias: 0.758486, T: 1800, Avg. loss: 9.128900\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1183.43, NNZs: 81919, Bias: 0.855145, T: 2400, Avg. loss: 2.422301\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1014.45, NNZs: 83024, Bias: 0.882336, T: 3000, Avg. loss: 0.506741\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 101.80, NNZs: 63032, Bias: 0.139221, T: 600, Avg. loss: 16.751760\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 60.90, NNZs: 84018, Bias: 0.130859, T: 1200, Avg. loss: 2.139186\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.44, NNZs: 90575, Bias: 0.134046, T: 1800, Avg. loss: 0.309152\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.57, NNZs: 94696, Bias: 0.133605, T: 2400, Avg. loss: 0.094375\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27.39, NNZs: 96872, Bias: 0.135181, T: 3000, Avg. loss: 0.023405\n",
      "Total training time: 0.08 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 101.71, NNZs: 61705, Bias: 0.020057, T: 600, Avg. loss: 17.304021\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 62.15, NNZs: 81572, Bias: 0.021789, T: 1200, Avg. loss: 2.438093\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.68, NNZs: 87307, Bias: 0.034234, T: 1800, Avg. loss: 0.273607\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.65, NNZs: 89803, Bias: 0.032010, T: 2400, Avg. loss: 0.077130\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27.17, NNZs: 90539, Bias: 0.032038, T: 3000, Avg. loss: 0.010703\n",
      "Total training time: 0.08 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 94.60, NNZs: 51377, Bias: 0.005182, T: 600, Avg. loss: 15.060964\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 60.15, NNZs: 73573, Bias: 0.016313, T: 1200, Avg. loss: 2.399004\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 43.42, NNZs: 82189, Bias: 0.016940, T: 1800, Avg. loss: 0.449175\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.68, NNZs: 85856, Bias: 0.013292, T: 2400, Avg. loss: 0.113991\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27.14, NNZs: 86144, Bias: 0.016287, T: 3000, Avg. loss: 0.005751\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 51.60, NNZs: 62014, Bias: 0.113646, T: 600, Avg. loss: 9.287036\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.49, NNZs: 86722, Bias: 0.101376, T: 1200, Avg. loss: 1.452802\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 22.85, NNZs: 97772, Bias: 0.103155, T: 1800, Avg. loss: 0.244296\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.55, NNZs: 100395, Bias: 0.102208, T: 2400, Avg. loss: 0.053535\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.18, NNZs: 101521, Bias: 0.102488, T: 3000, Avg. loss: 0.007956\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 53.19, NNZs: 62511, Bias: 0.032670, T: 600, Avg. loss: 10.446547\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 32.24, NNZs: 84076, Bias: 0.035343, T: 1200, Avg. loss: 1.346409\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 22.44, NNZs: 89231, Bias: 0.043014, T: 1800, Avg. loss: 0.149013\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.11, NNZs: 90943, Bias: 0.041606, T: 2400, Avg. loss: 0.034502\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 13.97, NNZs: 92304, Bias: 0.041939, T: 3000, Avg. loss: 0.017726\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 50.85, NNZs: 53857, Bias: -0.037617, T: 600, Avg. loss: 8.988644\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.24, NNZs: 75316, Bias: -0.026281, T: 1200, Avg. loss: 1.328357\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 22.20, NNZs: 83507, Bias: -0.025703, T: 1800, Avg. loss: 0.245386\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.15, NNZs: 86600, Bias: -0.026794, T: 2400, Avg. loss: 0.046630\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 13.93, NNZs: 87830, Bias: -0.027251, T: 3000, Avg. loss: 0.013237\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 11.73, NNZs: 71820, Bias: 0.040530, T: 600, Avg. loss: 3.149772\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6.91, NNZs: 94993, Bias: 0.041498, T: 1200, Avg. loss: 0.412794\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5.00, NNZs: 103407, Bias: 0.041203, T: 1800, Avg. loss: 0.081760\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.00, NNZs: 106623, Bias: 0.040746, T: 2400, Avg. loss: 0.041847\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.44, NNZs: 108799, Bias: 0.040797, T: 3000, Avg. loss: 0.030326\n",
      "Total training time: 0.06 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 11.55, NNZs: 67986, Bias: 0.031499, T: 600, Avg. loss: 3.160551\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6.87, NNZs: 89192, Bias: 0.032395, T: 1200, Avg. loss: 0.416443\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5.00, NNZs: 95830, Bias: 0.032962, T: 1800, Avg. loss: 0.093014\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.06, NNZs: 98850, Bias: 0.034606, T: 2400, Avg. loss: 0.049500\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.47, NNZs: 100336, Bias: 0.034477, T: 3000, Avg. loss: 0.028277\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 11.21, NNZs: 60181, Bias: -0.029037, T: 600, Avg. loss: 2.759678\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6.83, NNZs: 83868, Bias: -0.027168, T: 1200, Avg. loss: 0.465503\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5.01, NNZs: 91544, Bias: -0.027334, T: 1800, Avg. loss: 0.077271\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.02, NNZs: 95326, Bias: -0.026110, T: 2400, Avg. loss: 0.039028\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.44, NNZs: 96933, Bias: -0.026465, T: 3000, Avg. loss: 0.030898\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 5.99, NNZs: 76198, Bias: 0.025829, T: 600, Avg. loss: 1.907477\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3.75, NNZs: 101798, Bias: 0.025413, T: 1200, Avg. loss: 0.331469\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.91, NNZs: 108989, Bias: 0.025570, T: 1800, Avg. loss: 0.115979\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.50, NNZs: 110142, Bias: 0.025874, T: 2400, Avg. loss: 0.070510\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.28, NNZs: 110663, Bias: 0.025599, T: 3000, Avg. loss: 0.063082\n",
      "Total training time: 0.06 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 6.09, NNZs: 72733, Bias: 0.025390, T: 600, Avg. loss: 2.106198\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3.77, NNZs: 94811, Bias: 0.026383, T: 1200, Avg. loss: 0.329527\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.92, NNZs: 99644, Bias: 0.027813, T: 1800, Avg. loss: 0.119594\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.53, NNZs: 102648, Bias: 0.028099, T: 2400, Avg. loss: 0.088039\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.32, NNZs: 103535, Bias: 0.028281, T: 3000, Avg. loss: 0.066430\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 6.11, NNZs: 68784, Bias: -0.012391, T: 600, Avg. loss: 1.930140\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3.73, NNZs: 90093, Bias: -0.012093, T: 1200, Avg. loss: 0.310860\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.93, NNZs: 96917, Bias: -0.010879, T: 1800, Avg. loss: 0.118377\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.51, NNZs: 97825, Bias: -0.010587, T: 2400, Avg. loss: 0.074631\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.31, NNZs: 98022, Bias: -0.010282, T: 3000, Avg. loss: 0.062946\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.47, NNZs: 100461, Bias: 0.012414, T: 600, Avg. loss: 1.215260\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.15, NNZs: 111761, Bias: 0.012564, T: 1200, Avg. loss: 0.485309\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.09, NNZs: 112168, Bias: 0.012531, T: 1800, Avg. loss: 0.413033\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.08, NNZs: 112186, Bias: 0.012447, T: 2400, Avg. loss: 0.376772\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.06, NNZs: 112193, Bias: 0.012486, T: 3000, Avg. loss: 0.354673\n",
      "Total training time: 0.06 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.40, NNZs: 88966, Bias: 0.013344, T: 600, Avg. loss: 1.187193\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.13, NNZs: 103822, Bias: 0.013560, T: 1200, Avg. loss: 0.526635\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.08, NNZs: 104833, Bias: 0.013593, T: 1800, Avg. loss: 0.434142\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.05, NNZs: 104853, Bias: 0.013535, T: 2400, Avg. loss: 0.393224\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.04, NNZs: 104869, Bias: 0.013568, T: 3000, Avg. loss: 0.380246\n",
      "Total training time: 0.07 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.42, NNZs: 84546, Bias: 0.003056, T: 600, Avg. loss: 1.102052\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.12, NNZs: 99918, Bias: 0.002998, T: 1200, Avg. loss: 0.514884\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.08, NNZs: 101444, Bias: 0.003147, T: 1800, Avg. loss: 0.428994\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.05, NNZs: 101457, Bias: 0.003237, T: 2400, Avg. loss: 0.393398\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.04, NNZs: 101477, Bias: 0.003258, T: 3000, Avg. loss: 0.372245\n",
      "Total training time: 0.06 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 2048.55, NNZs: 85318, Bias: -0.338045, T: 900, Avg. loss: 169.336104\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1644.15, NNZs: 115054, Bias: 0.034803, T: 1800, Avg. loss: 39.867666\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1295.61, NNZs: 123110, Bias: 0.395884, T: 2700, Avg. loss: 4.710805\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1066.70, NNZs: 127618, Bias: 0.430945, T: 3600, Avg. loss: 2.102310\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 906.17, NNZs: 130704, Bias: 0.429860, T: 4500, Avg. loss: 1.029356\n",
      "Total training time: 0.07 seconds.\n",
      "Wall time: 1.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=2904,\n",
       "       shuffle=True, tol=None, verbose=5, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [0.0001, 0.005, 0.01, 0.05, 0.1, 0.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.51222222222222225, {'alpha': 0.0001})"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_, clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:   0.52\n",
      "Recall:   0.53\n",
      "F1-measure:   0.52\n",
      "Accuracy:   0.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.55      0.56       140\n",
      "          1       0.48      0.50      0.49       118\n",
      "\n",
      "avg / total       0.53      0.53      0.53       258\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAEFCAYAAAAoprYVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAADMJJREFUeJzt3H2QVfV5wPHv5W2XAIviWEOBhQD2\nZ6yKUdQYtcm0DRISlNSXNhontdowWoza0cpEY+1ooybUEIIvUaJjsca2IqOxI6XNmJkElVgpZmuY\np6KkJhqiYgRRQJDbP+7FrtTlJbIent3vZ2Zn55577znPhTPfe+65B2r1eh1JUg59qh5AkrTrjLYk\nJWK0JSkRoy1JiRhtSUrEaEtSIv2qHkA9RymlL3AhcAaNfWsA8D3gyojY9B7WeR/wYWBORMzdzedP\nBGZGxKm/yfb3tFLKUGBhRPx+F/cvBz4REa++v5MpC6OtPelmYF/gDyJibSllEPAPwDzgrN9wnSOA\nE4FBEfHW7j45Iv4D2CuC3bQvcHRXd0bE4e/jLEqo5j+u0Z5QShkDPAUMj4h1nZZ/EDguIhY0jzJv\nBA4H6sBDwJcjYkspZSNwHTAJGA58DbgLWAoUoAM4BVgJ7B8RLzfXXwf2BzYCdwAHAluBJ4DpwO8B\ncyPikN3dfkTc/C6vcyNwA/CHwGDgKuA04FDgBWBqRLxeSvmz5vYHAMOA6yLi5lLKw82ZOoAjgTeA\n+4EJwJnA483X8xc03qxOaN5eBpwZEQ/v+t+KeiLPaWtPORJ4qnOwASJidUQsaN6cA6yhEbiJNEJ1\nSfO+FuDliPgYjSPjbwCbgSnAhog4PCKe2cH2PwsMaR6pHtVcNna7x+zW9kspre+ynRZgdUQcDdxJ\n41PERcDBwFDg5FLKYODPgSkR8RHgj2m8CQGc3en1vEXzFFJElOangm2uab7+S4H5NN54DLaMtvaY\nrex8f/oUjfjUm+e4b2ku2+b+5u9lNOI4aDe2/yPgd0spPwBmArMjYmU3bX/bm9AzQEdEPB8RW4FV\nwLCIWA98Bvh0KeVq4HIaR+Vd+eH2C5pBPxO4DKgB1+7g+epFjLb2lKXAh0spQzovLKWMKKX8Syll\nII39rfP5uD5A/063NwBExLbH1LrYVq257gHbFkTEKmA8jbi1Af9eSpm63fP21PY7f6m6efs7Sykj\ngeXAaBpvJld0sZ5t1nexfHRzpnE0zoVLRlt7RkS8QONLx9tLKW0Azd83AWsiYgPwr8CMUkqtlNIC\nfBH4t93c1Es0Tm1A4yoVmts6j8Y57cURcVlzW0ds99w9sf1dMbE55zXAYhpH3duuhNkC9C2ldPWG\nQPOx+9D48/xT4LvAd7phTiVktLUnnQ/8FHikeena0ubtc5v3fwn4LRpfwnUAAfztbm7jS8CNpZRl\nNC4D/GVz+d8DfYGfllKeoHF+ec67PPe9bn9XLAZ+0Vz/CqCdRsTHN+f9MfBUKWW/HazjNuDBiFhM\n48vOsaWU87thViXj1SOSlIhH2pKUiNGWpESMtiQlYrQlKZFu/b9HDhv9cb/l1F7podsur3oEqUsj\nJk3q8pJQj7QlKRGjLUmJGG1JSsRoS1IiRluSEjHakpSI0ZakRIy2JCVitCUpEaMtSYkYbUlKxGhL\nUiJGW5ISMdqSlIjRlqREjLYkJWK0JSkRoy1JiRhtSUrEaEtSIkZbkhIx2pKUiNGWpESMtiQlYrQl\nKRGjLUmJGG1JSsRoS1IiRluSEjHakpSI0ZakRIy2JCVitCUpEaMtSYkYbUlKxGhLUiJGW5ISMdqS\nlIjRlqREjLYkJWK0JSkRoy1JiRhtSUrEaEtSIkZbkhIx2pKUiNGWpESMtiQlYrQlKRGjLUmJ9Kt6\nAL27k06dzMmnTgagpWUA5eDxrHrmOV5btx6AD41r5/57F/HN62+tckz1UncvXswjHR1sfustTj7h\nBA4eM4Yb7rmHer3OuBEjuOC00+jbx2PC7mC091IP3LuIB+5dBMCXr76Ihf/0EAu++z0ARowazqyb\nruLWb82vckT1Usuffpr/WrWKORdfzKbNm/nH73+fRzs6OGfqVCaMH8/18+fzSEcHJ0yYUPWoPdIu\nR7uU0icitnbnMPr/Dj60MO7AMXz1K7PfXnbZX1/A7Ou+zYY3NlQ4mXqrx1esYOzw4Vw5bx5vbNzI\n9GnTOGvyZPr26cPmLVt45bXX2HfIkKrH7LF2GO1SyljgBmAisKWU0gfoAC6OiP9+H+br9c6d8Xlu\n+eadb98+8KCxDBr8AZYuWVbhVOrN1q5fz69+/Wu+On06v1yzhituvZU7r7iC1a+8wqVz5zKotZVR\nBxxQ9Zg91s5OOs0Dro2IkRExJiLagauBO7p/NA1pG8yHxrXz+KP/+fayz3x2EgvuebDCqdTbtQ0a\nxFEHHUT/fv1oP+AABvTrx6vr1/PBYcOYf+WVTD3+eG6+776qx+yxdhbt1ohY2nlBRDzWjfOokyOP\nPozHfvTEO5Ydc9wRLPnBjyuaSIJDx43j8RUrqNfrvLx2LRvffJOv3303v3jxRQA+0NJCrVareMqe\na2fntJ8spdwOLALWAkOAKcBPunswwZhx7Tz/3AvvWLbf/sNY++q6iiaS4NhDDuEnK1dy/qxZbK3X\nufD00xnY0sL1d91F/379aOnfn0vOOKPqMXusWr1e7/LOUkoNmAYcD7QB64AlwMKI6PqJTYeN/vhO\nHyNV4aHbLq96BKlLIyZN6vKjyg6PtJthXtj8kSRVzKvfJSkRoy1JiRhtSUrEaEtSIkZbkhIx2pKU\niNGWpESMtiQlYrQlKRGjLUmJGG1JSsRoS1IiRluSEjHakpSI0ZakRIy2JCVitCUpEaMtSYkYbUlK\nxGhLUiJGW5ISMdqSlIjRlqREjLYkJWK0JSkRoy1JiRhtSUrEaEtSIkZbkhIx2pKUiNGWpESMtiQl\nYrQlKRGjLUmJGG1JSsRoS1IiRluSEjHakpSI0ZakRIy2JCVitCUpEaMtSYkYbUlKxGhLUiJGW5IS\nMdqSlIjRlqREjLYkJWK0JSkRoy1JidTq9Xq3rfzNdWu6b+WS1EMNaNuv1tV9HmlLUiJGW5ISMdqS\nlIjRlqREjLYkJWK0JSkRoy1JiRhtSUrEaEtSIkZbkhIx2pKUiNGWpESMtiQlYrQlKRGjLUmJGG1J\nSsRoS1IiRluSEjHakpSI0ZakRIy2JCVitCUpEaMtSYkYbUlKxGhLUiJGW5ISMdqSlIjRlqREjLYk\nJWK0JSkRoy1JiRhtSUrEaEtSIkZbkhIx2pKUiNGWpESMtiQlYrQlKRGjLUmJGG1JSsRoS1IiRluS\nEjHakpSI0ZakRIy2JCVitCUpEaMtSYkYbUlKxGhLUiL9qh5AXTvtzC8wePBgAEb89nCmnPhJvvGt\nmxg4cCDHHXsM0885u+IJ1Vu5b1bHaO+lNm3aBMAd374RgK1bt3LiSadw+y1zGTVyBDO/chXLlj/J\nEYdPqHJM9ULum9Xy9MheKp5eycaNm/jijAs557wZLFv+JG1tQxg1cgQAH5lwGMuWP1nxlOqN3Der\n5ZH2Xqq1tZUvfP5znDLtJP7nuZ9z3oV/Sb1e59mf/YzRo0bxwyWPUn7nwKrHVC/kvlmtHUa7lPIw\n0LLd4hpQj4iPddtUYkz7KNpHjqRWqzFmdDv7DB3KJRddwNXXfp22tiGMGd3OvvsMrXpM9ULum9Xa\n2emRmcBg4Czgc82fP2n+Vjda+MCDzJo9B4AXX3qJ9a+/zpJHH+PG2bOY/bVr+fnzz/PRo4+qeEr1\nRu6b1arV6/UdPqCUcimwMiIW7u7K31y3ZscrV5c2b97M5X9zDatX/4parcbFM85n5bPPcs8/30dL\n6wA+PflEzjj91KrHVC/kvtn9BrTtV+vqvp1G+70w2pK0+3YUba8ekaREjLYkJWK0JSkRoy1JiRht\nSUrEaEtSIkZbkhIx2pKUiNGWpESMtiQlYrQlKRGjLUmJGG1JSsRoS1IiRluSEjHakpSI0ZakRIy2\nJCVitCUpEaMtSYkYbUlKxGhLUiJGW5ISMdqSlIjRlqREjLYkJWK0JSkRoy1JiRhtSUrEaEtSIkZb\nkhIx2pKUiNGWpESMtiQlYrQlKRGjLUmJGG1JSsRoS1IiRluSEjHakpSI0ZakRIy2JCVitCUpEaMt\nSYkYbUlKxGhLUiJGW5ISMdqSlIjRlqREjLYkJVKr1+tVzyBJ2kUeaUtSIkZbkhIx2pKUiNGWpESM\ntiQlYrQlKRGjLUmJ9Kt6AO1cKaUPcBMwAdgEnBsRK6udSvo/pZRjgOsj4hNVz9LTeaSdwzSgNSKO\nBWYCf1fxPNLbSil/BcwDWquepTcw2jkcDywCiIjHgInVjiO9wzPAH1U9RG9htHNoA9Z2uv1WKcVT\nW9orRMQCYHPVc/QWRjuHdcCQTrf7RMSWqoaRVB2jncMSYApAKeWjQEe140iqih+xc1gIfLKU8ghQ\nA86ueB5JFfG/ZpWkRDw9IkmJGG1JSsRoS1IiRluSEjHakpSI0ZakRIy2JCXyvz/3J66tCbsDAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x59c45e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predictions, average='macro')))\n",
    "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, predictions, average='macro')))\n",
    "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, predictions, average='macro')))\n",
    "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(classification_report(y_test, predictions))\n",
    "labels = clf.classes_\n",
    "sns.heatmap(data=confusion_matrix(y_test, predictions), annot=True, fmt=\"d\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(estimator=classifier, param_grid=params, scoring='accuracy', verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] alpha=0.0001 ....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 17.84, NNZs: 30, Bias: -6.272780, T: 600, Avg. loss: 3.302744\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 18.10, NNZs: 30, Bias: 0.059777, T: 1200, Avg. loss: 2.314547\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.47, NNZs: 30, Bias: 3.704730, T: 1800, Avg. loss: 1.871690\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.37, NNZs: 30, Bias: 0.206024, T: 2400, Avg. loss: 1.664928\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.71, NNZs: 30, Bias: 0.235639, T: 3000, Avg. loss: 1.480547\n",
      "Total training time: 0.08 seconds.\n",
      "[CV] ......................... alpha=0.0001, score=0.52, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] alpha=0.0001 ....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 20.29, NNZs: 30, Bias: -6.175947, T: 600, Avg. loss: 3.175928\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.88, NNZs: 30, Bias: -4.467091, T: 1200, Avg. loss: 2.287171\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.39, NNZs: 30, Bias: 3.643293, T: 1800, Avg. loss: 1.940050\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 23.10, NNZs: 30, Bias: 3.047672, T: 2400, Avg. loss: 1.662640\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.72, NNZs: 30, Bias: -2.399268, T: 3000, Avg. loss: 1.447135\n",
      "Total training time: 0.05 seconds.\n",
      "[CV] ........... alpha=0.0001, score=0.5033333333333333, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] alpha=0.0001 ....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 16.41, NNZs: 30, Bias: 6.234085, T: 600, Avg. loss: 3.248832\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 18.40, NNZs: 30, Bias: -4.513182, T: 1200, Avg. loss: 2.492977\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 20.49, NNZs: 30, Bias: 0.086791, T: 1800, Avg. loss: 1.926461\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.47, NNZs: 30, Bias: 3.075843, T: 2400, Avg. loss: 1.633112\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.43, NNZs: 30, Bias: 0.174106, T: 3000, Avg. loss: 1.589718\n",
      "Total training time: 0.05 seconds.\n",
      "[CV] .......... alpha=0.0001, score=0.48333333333333334, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] alpha=0.005 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.18, NNZs: 30, Bias: -0.318224, T: 600, Avg. loss: 1.157170\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.12, NNZs: 30, Bias: 0.310880, T: 1200, Avg. loss: 0.981817\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.24, NNZs: 30, Bias: 0.159338, T: 1800, Avg. loss: 1.032429\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.20, NNZs: 30, Bias: 0.722806, T: 2400, Avg. loss: 0.970712\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.24, NNZs: 30, Bias: -0.232153, T: 3000, Avg. loss: 1.016279\n",
      "Total training time: 0.05 seconds.\n",
      "[CV] ............ alpha=0.005, score=0.5033333333333333, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] alpha=0.005 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.24, NNZs: 30, Bias: -1.215583, T: 600, Avg. loss: 1.122928\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.25, NNZs: 30, Bias: 0.202905, T: 1200, Avg. loss: 0.971798\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.41, NNZs: 30, Bias: 0.316151, T: 1800, Avg. loss: 1.014610\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.44, NNZs: 30, Bias: 0.487940, T: 2400, Avg. loss: 0.997067\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.48, NNZs: 30, Bias: -0.240309, T: 3000, Avg. loss: 0.982476\n",
      "Total training time: 0.05 seconds.\n",
      "[CV] ............ alpha=0.005, score=0.5033333333333333, total=   0.0s\n",
      "[CV] alpha=0.005 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.12, NNZs: 30, Bias: 0.372174, T: 600, Avg. loss: 1.118581\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.17, NNZs: 30, Bias: -0.602534, T: 1200, Avg. loss: 1.035192\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.21, NNZs: 30, Bias: -0.182868, T: 1800, Avg. loss: 1.010796\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.23, NNZs: 30, Bias: 0.055237, T: 2400, Avg. loss: 0.990665\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.27, NNZs: 30, Bias: -0.553236, T: 3000, Avg. loss: 1.016087\n",
      "Total training time: 0.05 seconds.\n",
      "[CV] ............ alpha=0.005, score=0.5033333333333333, total=   0.0s\n",
      "[CV] alpha=0.01 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.67, NNZs: 30, Bias: 0.248056, T: 600, Avg. loss: 1.102257\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.62, NNZs: 30, Bias: 0.659457, T: 1200, Avg. loss: 0.963460\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.66, NNZs: 30, Bias: -0.065544, T: 1800, Avg. loss: 1.024806\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.66, NNZs: 30, Bias: 0.517926, T: 2400, Avg. loss: 0.984350\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.67, NNZs: 30, Bias: 0.311076, T: 3000, Avg. loss: 1.015651\n",
      "Total training time: 0.05 seconds.\n",
      "[CV] ............ alpha=0.01, score=0.49666666666666665, total=   0.0s\n",
      "[CV] alpha=0.01 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.82, NNZs: 30, Bias: -0.767942, T: 600, Avg. loss: 1.067744\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.78, NNZs: 30, Bias: 0.592572, T: 1200, Avg. loss: 0.987215\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.82, NNZs: 30, Bias: -0.335256, T: 1800, Avg. loss: 1.014073\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.83, NNZs: 30, Bias: 0.109135, T: 2400, Avg. loss: 0.995141\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.85, NNZs: 30, Bias: -0.032087, T: 3000, Avg. loss: 1.010465\n",
      "Total training time: 0.06 seconds.\n",
      "[CV] ............ alpha=0.01, score=0.49333333333333335, total=   0.0s\n",
      "[CV] alpha=0.01 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.68, NNZs: 30, Bias: 0.038294, T: 600, Avg. loss: 1.048034\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.67, NNZs: 30, Bias: -0.503024, T: 1200, Avg. loss: 1.019848\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.70, NNZs: 30, Bias: -0.521245, T: 1800, Avg. loss: 1.027841\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.70, NNZs: 30, Bias: -0.111353, T: 2400, Avg. loss: 1.004980\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.71, NNZs: 30, Bias: -0.177757, T: 3000, Avg. loss: 1.013908\n",
      "Total training time: 0.05 seconds.\n",
      "[CV] ............. alpha=0.01, score=0.5033333333333333, total=   0.0s\n",
      "[CV] alpha=0.05 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.15, NNZs: 30, Bias: -0.042534, T: 600, Avg. loss: 1.031821\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.15, NNZs: 30, Bias: -0.147930, T: 1200, Avg. loss: 1.011991\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.15, NNZs: 30, Bias: -0.197858, T: 1800, Avg. loss: 1.004912\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.15, NNZs: 30, Bias: -0.274145, T: 2400, Avg. loss: 1.002967\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.15, NNZs: 30, Bias: -0.301132, T: 3000, Avg. loss: 1.000934\n",
      "Total training time: 0.05 seconds.\n",
      "[CV] ............. alpha=0.05, score=0.5033333333333333, total=   0.0s\n",
      "[CV] alpha=0.05 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.18, NNZs: 30, Bias: -0.015212, T: 600, Avg. loss: 1.034258\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.19, NNZs: 30, Bias: -0.237119, T: 1200, Avg. loss: 1.010586\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.19, NNZs: 30, Bias: -0.296599, T: 1800, Avg. loss: 1.003703\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.19, NNZs: 30, Bias: -0.362522, T: 2400, Avg. loss: 1.001314\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.19, NNZs: 30, Bias: -0.382891, T: 3000, Avg. loss: 0.999675\n",
      "Total training time: 0.05 seconds.\n",
      "[CV] ............. alpha=0.05, score=0.5033333333333333, total=   0.0s\n",
      "[CV] alpha=0.05 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.16, NNZs: 30, Bias: -0.771956, T: 600, Avg. loss: 1.004913\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.15, NNZs: 30, Bias: -0.683260, T: 1200, Avg. loss: 1.003426\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.15, NNZs: 30, Bias: -0.702782, T: 1800, Avg. loss: 1.001735\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.15, NNZs: 30, Bias: -0.744239, T: 2400, Avg. loss: 0.999201\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.15, NNZs: 30, Bias: -0.757491, T: 3000, Avg. loss: 0.997896\n",
      "Total training time: 0.05 seconds.\n",
      "[CV] ............. alpha=0.05, score=0.5033333333333333, total=   0.0s\n",
      "[CV] alpha=0.1 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 30, Bias: -0.506457, T: 600, Avg. loss: 1.022918\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.07, NNZs: 30, Bias: -0.559319, T: 1200, Avg. loss: 1.002788\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.07, NNZs: 30, Bias: -0.584339, T: 1800, Avg. loss: 0.999224\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.07, NNZs: 30, Bias: -0.622590, T: 2400, Avg. loss: 0.998249\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.08, NNZs: 30, Bias: -0.636101, T: 3000, Avg. loss: 0.997230\n",
      "Total training time: 0.05 seconds.\n",
      "[CV] .............. alpha=0.1, score=0.5033333333333333, total=   0.0s\n",
      "[CV] alpha=0.1 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.09, NNZs: 30, Bias: -0.310046, T: 600, Avg. loss: 1.025609\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.09, NNZs: 30, Bias: -0.421830, T: 1200, Avg. loss: 1.003282\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.10, NNZs: 30, Bias: -0.451650, T: 1800, Avg. loss: 0.999824\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.10, NNZs: 30, Bias: -0.484700, T: 2400, Avg. loss: 0.998628\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.10, NNZs: 30, Bias: -0.494891, T: 3000, Avg. loss: 0.997809\n",
      "Total training time: 0.05 seconds.\n",
      "[CV] .............. alpha=0.1, score=0.5033333333333333, total=   0.0s\n",
      "[CV] alpha=0.1 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.08, NNZs: 30, Bias: -0.071928, T: 600, Avg. loss: 1.008671\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.08, NNZs: 30, Bias: -0.134773, T: 1200, Avg. loss: 1.005008\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.08, NNZs: 30, Bias: -0.144512, T: 1800, Avg. loss: 1.002230\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.08, NNZs: 30, Bias: -0.165284, T: 2400, Avg. loss: 1.000962\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.08, NNZs: 30, Bias: -0.171907, T: 3000, Avg. loss: 1.000315\n",
      "Total training time: 0.07 seconds.\n",
      "[CV] .............. alpha=0.1, score=0.5033333333333333, total=   0.0s\n",
      "[CV] alpha=0.5 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 30, Bias: 0.196730, T: 600, Avg. loss: 1.012751\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.02, NNZs: 30, Bias: 0.186124, T: 1200, Avg. loss: 1.002545\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.02, NNZs: 30, Bias: 0.181108, T: 1800, Avg. loss: 1.001831\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 30, Bias: 0.173436, T: 2400, Avg. loss: 1.001635\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.02, NNZs: 30, Bias: 0.170730, T: 3000, Avg. loss: 1.001431\n",
      "Total training time: 0.07 seconds.\n",
      "[CV] ............. alpha=0.5, score=0.49666666666666665, total=   0.0s\n",
      "[CV] alpha=0.5 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 30, Bias: 0.647525, T: 600, Avg. loss: 1.014652\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.02, NNZs: 30, Bias: 0.624995, T: 1200, Avg. loss: 1.005386\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.02, NNZs: 30, Bias: 0.619014, T: 1800, Avg. loss: 1.004692\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 30, Bias: 0.612386, T: 2400, Avg. loss: 1.004453\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.02, NNZs: 30, Bias: 0.610346, T: 3000, Avg. loss: 1.004289\n",
      "Total training time: 0.05 seconds.\n",
      "[CV] ............. alpha=0.5, score=0.49666666666666665, total=   0.0s\n",
      "[CV] alpha=0.5 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 30, Bias: 0.595266, T: 600, Avg. loss: 1.011969\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.02, NNZs: 30, Bias: 0.582604, T: 1200, Avg. loss: 1.005072\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.02, NNZs: 30, Bias: 0.580661, T: 1800, Avg. loss: 1.004513\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 30, Bias: 0.576498, T: 2400, Avg. loss: 1.004258\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.02, NNZs: 30, Bias: 0.575173, T: 3000, Avg. loss: 1.004128\n",
      "Total training time: 0.05 seconds.\n",
      "[CV] ............. alpha=0.5, score=0.49666666666666665, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    1.3s finished\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.22, NNZs: 30, Bias: 1.078365, T: 900, Avg. loss: 1.083491\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.14, NNZs: 30, Bias: -0.485631, T: 1800, Avg. loss: 1.002422\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.16, NNZs: 30, Bias: 0.103781, T: 2700, Avg. loss: 1.025789\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.12, NNZs: 30, Bias: 0.052351, T: 3600, Avg. loss: 0.988375\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.16, NNZs: 30, Bias: -0.186706, T: 4500, Avg. loss: 1.017681\n",
      "Total training time: 0.04 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=2904,\n",
       "       shuffle=True, tol=None, verbose=5, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [0.0001, 0.005, 0.01, 0.05, 0.1, 0.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=5)"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(b, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5033333333333333, {'alpha': 0.005})"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_, clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:   0.44\n",
      "Recall:   0.50\n",
      "F1-measure:   0.36\n",
      "Accuracy:   0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.99      0.70       140\n",
      "          1       0.33      0.01      0.02       118\n",
      "\n",
      "avg / total       0.45      0.54      0.39       258\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAEFCAYAAAAoprYVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+X+hCshM6hPhbwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x630b0198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, predictions, average='macro')))\n",
    "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, predictions, average='macro')))\n",
    "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, predictions, average='macro')))\n",
    "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(classification_report(y_test, predictions))\n",
    "labels = clf.classes_\n",
    "sns.heatmap(data=confusion_matrix(y_test, predictions), annot=True, fmt=\"d\", cbar=False, xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. Творческая\n",
    "Придумайте и попытайтесь сделать еще что-нибудь, чтобы улучшить качество классификации. \n",
    "Направления развития:\n",
    "* Морфологический признаки: \n",
    "    * использовать в качестве признаков только существительные или только именованные сущности;\n",
    "* Модели скрытых тем:\n",
    "    * использовать в качестве признаков скрытые темы;\n",
    "    * использовать в качестве признаков динамические скрытые темы \n",
    "    пример тут: (https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/dtm_example.ipynb)\n",
    "* Синтаксические признаки:\n",
    "    * использовать SOV-тройки в качестве признаков\n",
    "    * кластеризовать SOV-тройки по эмбеддингам глаголов (обученные word2vec модели можно скачать отсюда: (http://rusvectores.org/ru/models/) и использовать только центроиды кластеров в качестве признаков\n",
    "* что-нибудь еще     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import ldamodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import *\n",
    "texts = [intersection.text.iloc[i].split() for i in range(len(intersection))]\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda = ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=10,\n",
    "                        alpha='auto', eta='auto', iterations = 20, passes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логарифмическая перплексивность модели составляет -7.395395065275654\n"
     ]
    }
   ],
   "source": [
    "print('Логарифмическая перплексивность модели составляет {0}'\n",
    "      .format(lda.log_perplexity(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тема:0 Словарный состав:0.041*\"газпром\" + 0.020*\"нефть\" + 0.016*\"компания\" + 0.014*\"газ\" + 0.010*\"год\" + 0.009*\"месторождение\" + 0.009*\"который\" + 0.008*\"проект\" + 0.007*\"цена\" + 0.005*\"российский\"\n",
      "\n",
      "Тема:1 Словарный состав:0.042*\"газпром\" + 0.014*\"компания\" + 0.014*\"газ\" + 0.010*\"российский\" + 0.009*\"который\" + 0.008*\"сообщать\" + 0.008*\"год\" + 0.007*\"украина\" + 0.007*\"поставка\" + 0.006*\"газовый\"\n",
      "\n",
      "Тема:2 Словарный состав:0.029*\"газпром\" + 0.016*\"компания\" + 0.010*\"газ\" + 0.007*\"нефть\" + 0.007*\"сообщать\" + 0.007*\"цена\" + 0.006*\"российский\" + 0.005*\"который\" + 0.005*\"сделка\" + 0.004*\"проект\"\n",
      "\n",
      "Тема:3 Словарный состав:0.024*\"газпром\" + 0.013*\"компания\" + 0.010*\"газ\" + 0.008*\"газпромбанк\" + 0.008*\"который\" + 0.007*\"сообщать\" + 0.007*\"год\" + 0.006*\"российский\" + 0.005*\"нефть\" + 0.005*\"источник\"\n",
      "\n",
      "Тема:4 Словарный состав:0.015*\"газпром\" + 0.007*\"газ\" + 0.007*\"год\" + 0.006*\"компания\" + 0.006*\"который\" + 0.004*\"газпром-медиа\" + 0.004*\"цена\" + 0.004*\"российский\" + 0.004*\"холдинг\" + 0.004*\"телеканал\"\n",
      "\n",
      "Тема:5 Словарный состав:0.033*\"газпром\" + 0.017*\"газ\" + 0.011*\"компания\" + 0.009*\"который\" + 0.009*\"нефть\" + 0.008*\"поставка\" + 0.007*\"российский\" + 0.006*\"год\" + 0.006*\"сообщать\" + 0.006*\"украина\"\n",
      "\n",
      "Тема:6 Словарный состав:0.039*\"газпром\" + 0.024*\"газ\" + 0.017*\"компания\" + 0.013*\"год\" + 0.010*\"российский\" + 0.008*\"цена\" + 0.008*\"нефть\" + 0.008*\"который\" + 0.008*\"рынок\" + 0.007*\"поставка\"\n",
      "\n",
      "Тема:7 Словарный состав:0.032*\"газпром\" + 0.023*\"компания\" + 0.015*\"год\" + 0.011*\"прибыль\" + 0.011*\"нефть\" + 0.009*\"чистый\" + 0.008*\"проект\" + 0.007*\"сообщать\" + 0.007*\"первый\" + 0.007*\"газ\"\n",
      "\n",
      "Тема:8 Словарный состав:0.020*\"газпром\" + 0.012*\"компания\" + 0.010*\"газпром-медиа\" + 0.007*\"нефть\" + 0.007*\"холдинг\" + 0.006*\"который\" + 0.006*\"становиться\" + 0.006*\"год\" + 0.005*\"группа\" + 0.005*\"российский\"\n",
      "\n",
      "Тема:9 Словарный состав:0.021*\"газпром\" + 0.010*\"газ\" + 0.009*\"год\" + 0.009*\"который\" + 0.009*\"компания\" + 0.005*\"украина\" + 0.005*\"становиться\" + 0.005*\"проект\" + 0.005*\"российский\" + 0.005*\"роснефть\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda.print_topics(-1):\n",
    "    print('Тема:{0} Словарный состав:{1}\\n'.format(idx, topic))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
